= Nvidia-GPU + Keras + Tensorflow + Pytorch Installation Instructions

This guide sets up a local development environment for Keras, Tensorflow and Pytorch on an Nvidia GPU. As we use Docker/Podman the image can easily be shipped to other machines, as long as they have the following things installed:

- Nvidia GPU
- Driver Version 545
- NVIDIA Container Toolkit

This guide was created using the following machine settings:
[source, bash]
----
hostnamectl
Operating System: Ubuntu 22.04.4 LTS
Kernel: Linux 6.5.0-28-generic
Architecture: x86-64
----

[source, bash]
----
lspci | grep -i nvidia
2b:00.0 VGA compatible controller: NVIDIA Corporation GA104 [GeForce RTX 3060 Ti Lite Hash Rate] (rev a1)
----

Concrete driver version:
545.23.08

Furthermore, we will install the following program versions:

- Python 3.11
- torch==2.3.0
- tensorflow==2.16.1
- keras==3.0.5

== Install GPU Driver
This part of the guide is based on the one of https://gist.github.com/MihailCosmin/affa6b1b71b43787e9228c25fe15aeba[MihailCosmin]:

1. Verify your GPU:
[source, bash]
lspci | grep -i nvidia

2. Remove previous GPU driver installations:
[source, bash]
sudo apt purge nvidia* -y
sudo apt remove nvidia-* -y
sudo rm /etc/apt/source, bashs.list.d/cuda*
sudo apt autoremove -y && sudo apt autoclean -y
sudo rm -rf /usr/local/cuda*

 3. Install the GPU driver:
[source, bash]
sudo apt update && sudo apt upgrade -y
sudo apt install g++ freeglut3-dev build-essential libx11-dev libxmu-dev libxi-dev libglu1-mesa libglu1-mesa-dev
sudo add-apt-repository ppa:graphics-drivers/ppa
sudo apt update
ubuntu-drivers devices
sudo apt install libnvidia-common-545 libnvidia-gl-545 nvidia-driver-545 -y

 4. Reboot the system
 5. Verify your installation:
[source, bash]
nvidia-smi

The driver version should start with 545. CUDA Version shows the latest possible CUDA version which can be installed, not the currently installed one. However, we do not need to install CUDA/CuDNN/TensorRT as those components only need to be installed inside the Docker/Podman container we will use.

== Install NVIDIA Container Toolkit

Install the https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html[NVIDIA Container Toolkit]
[source, bash]
sudo curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \
  && curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
    sudo tee /etc/apt/source, bashs.list.d/nvidia-container-toolkit.list
sudo sed -i -e '/experimental/ s/^#//g' /etc/apt/source, bashs.list.d/nvidia-container-toolkit.list
sudo sudo apt-get update
sudo sudo apt-get install -y nvidia-container-toolkit

Now choose between Docker and Podman.

=== Docker
1. To install podman use the `ubuntu-install-docker.sh` based on the https://docs.docker.com/engine/install/ubuntu/#install-using-the-repository[official installation instructions].

2. https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#configuring-docker[Configure Docker]:
[source, bash]
sudo nvidia-ctk runtime configure --runtime=docker
sudo systemctl restart docker

3. Confirm the installation:
[source, bash]
sudo docker run --rm --runtime=nvidia --gpus all ubuntu nvidia-smi

If no error is shown, your installation was successfully.

=== Podman
1. To install podman use the `ubuntu-install-podman.sh` based on https://askubuntu.com/questions/1414446/whats-the-recommended-way-of-installing-podman-4-in-ubuntu-22-04[this post].

2. https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/cdi-support.html#procedure[Configure Podman]:
[source, bash]
sudo nvidia-ctk cdi generate --output=/etc/cdi/nvidia.yaml

3. Confirm the installation:
[source, bash]
podman run --rm --device nvidia.com/gpu=all --security-opt=label=disable ubuntu nvidia-smi -L

If the output shows your GPU, the installation was successfully.

== Build your Docker/Podman image
From no on we only work with Dockerfiles which can then be shipped to any machine fulfilling the above requirements.

=== Dockerhub
I recommend creating a https://hub.docker.com/[Dockerhub] account where you can push/pull images to save them and transfer them between machines.
To login use the following commands. Please use either *podman* or *docker*!
[source, bash]
docker/podman login docker.io

Once you are logged in successfully, use these commands to pull/push your images:
[source, bash]
docker/podman pull/push docker.io/USERNAME/IMAGENAME:VERSION

=== Building an image
To build an image with tensorflow, pytorch and keras, use this command:
[source, bash]
docker/podman build -t USERNAME/IMAGENAME:VERSION .

Note that you can modify the requirements.txt as needed to adjust the installation.

=== Testing the image
To test the image, you can use the provided python file:
[source, bash]
sudo docker run --gpus all --rm IMAGENAME:VERSION python src/main.py

OR
[source, bash]
podman run --rm --device nvidia.com/gpu=all --security-opt=label=disable IMAGENAME:VERSION src/main.py

To test the image interactively, use these commands:
[source, bash]
sudo docker run --gpus all -it --rm IMAGENAME:VERSION bash

OR
[source, bash]
podman run --rm -it --device nvidia.com/gpu=all --security-opt=label=disable IMAGENAME:VERSION bash



== Outdated Notes
Installing cuda locally:
[source, bash]
sudo apt install cuda-11-8 cuda-drivers=545.23.08-1 -y

Docker
[source, bash]
sudo docker run --gpus all -it --rm tensorflow/tensorflow:latest-gpu python -c "import tensorflow as tf; print(tf.config.list_physical_devices())"
sudo docker run --gpus all -it --rm tensorflow/tensorflow:latest-gpu bash
sudo docker run --gpus all -it --rm -v /home/lukas/PycharmProjects/code-readability-classifier/tests/res/raw_datasets/combined:/app/dataset rc-gpu bash
python src/readability_classifier/main.py TRAIN -i dataset

Podman
[source, bash]
podman run --rm --device nvidia.com/gpu=all --security-opt=label=disable rc-gpu python -c "import tensorflow as tf; print(tf.config.list_physical_devices())"
podman run --rm -it --device nvidia.com/gpu=all --security-opt=label=disable rc-gpu bash

Other driver versions:

Also works with 525.147.05. Just replace 545 with 525 everywhere.

Exemplary cuda checker output (with 525):

[source, bash]
----
podman run -it --rm --device nvidia.com/gpu=all localhost/lukro2011/rc-gpu:2 python src/readability_classifier/utils/cuda-checker.py
Torch:
PyTorch version: 2.3.0+cu121
CUDA is available for torch:  True
PyTorch cuDNN version: 8902
Cuda version: 12.1

Tensorflow:
2024-06-04 08:43:20.924673: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-04 08:43:22.886002: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-06-04 08:43:22.889393: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-06-04 08:43:22.889565: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
Num GPUs Available:  1
Is built with CUDA: True
Tensorflow version: 2.16.1

Tensorflow GPU test:
2024-06-04 08:43:22.890825: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-06-04 08:43:22.890994: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-06-04 08:43:22.891163: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-06-04 08:43:24.906019: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-06-04 08:43:24.906230: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-06-04 08:43:24.906404: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2024-06-04 08:43:24.906749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4558 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:2b:00.0, compute capability: 8.6
tf.Tensor(
[[22. 28.]
 [49. 64.]], shape=(2, 2), dtype=float32)

Keras GPU test:
/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
Model: "sequential"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ dense (Dense)                   │ (None, 64)             │         2,112 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (None, 10)             │           650 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 2,762 (10.79 KB)
 Trainable params: 2,762 (10.79 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/10
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1717490606.595171      93 service.cc:145] XLA service 0x732afc007e30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1717490606.595201      93 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Ti, Compute Capability 8.6
2024-06-04 08:43:26.624197: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2024-06-04 08:43:27.078566: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8902
I0000 00:00:1717490607.612888      93 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
32/32 ━━━━━━━━━━━━━━━━━━━━ 2s 14ms/step - accuracy: 0.0929 - loss: 11.9733
Epoch 2/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 537us/step - accuracy: 0.1034 - loss: 13.3227
Epoch 3/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 497us/step - accuracy: 0.0970 - loss: 15.4647
Epoch 4/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 519us/step - accuracy: 0.0993 - loss: 17.3379
Epoch 5/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 519us/step - accuracy: 0.0995 - loss: 18.8004
Epoch 6/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 513us/step - accuracy: 0.0992 - loss: 20.1477
Epoch 7/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 545us/step - accuracy: 0.0977 - loss: 22.1397
Epoch 8/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 569us/step - accuracy: 0.1136 - loss: 23.7979
Epoch 9/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 542us/step - accuracy: 0.1029 - loss: 25.5751
Epoch 10/10
32/32 ━━━━━━━━━━━━━━━━━━━━ 0s 542us/step - accuracy: 0.1085 - loss: 27.6062
----
